---
title: "Chapter_9_Exercises"
author: "Colby S."
date: "4/8/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---
General Statistics

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

## Generate Sample Data
```

get a  basic statistical summary of your data
```{r 9.1 Summarizing Your Data}
# predict the output of the summary function to each of the variables then apply the summary function. Did the output surprise you? 
# bonus: share a way to get more meaningful output

## VECTOR
vec <- rnorm(100, mean = 100, sd = 15)
# summary(vec)

## FACTOR
factor_lvls <- factor(c("yes", "no", "maybe"), levels = c("yes", "no", "maybe"))
fac <- sample(factor_lvls, size = 100, prob = c(0.6, 0.3, 0.1), replace = TRUE)
# summary(fac)

## CHARACTER VECTOR
char <- c("What is returned when you summarise a character vector with one string")
# summary(char)
# length(char)
char2 <- c("how", "about", "when", "there's", "two", "characters")
# summary(char2)
# bonus: how many characters (letters/spaces/punctuation/etc) are in the vector "char")
nchar(char2)

## MATRIX
mat <- cbind(
  rnorm(100, mean = 100, sd = 15),
  rnorm(100, mean = 50, sd = 30),
  rnorm(100, mean = 80, sd = 5)
)
# summary(mat)

## DATAFRAME
# Apply the summary function to df.
df <- data.frame(
  char, fac, vec
)
# summary(df)

## LIST
# apply the summary function to each element in list1
list1 <- list(2, "hello", c(3,5,4), 1:5, list(FALSE, c("this", "is","a","list"),c(FALSE,TRUE,TRUE,TRUE,FALSE)))
summary(list1)
purrr::map(list1, summary)
```

count the relative frequency of certain observations in your sample
```{r 9.2 Calculating Relative Frequencies}
set.seed(120)
df_effects <- data.frame(
  before = rnorm(1000, 100, 20),
  after = rnorm(1000, 120, 20),
  label = sample(c("NJ", "FL"), 1000, prob = c(0.6, 0.4), replace = TRUE)
)
before <- as.vector(df_effects$before)
after <- as.vector(df_effects$after)
label <- as.vector(df_effects$label)

time_series <- rnorm(1000, 100, 20)
# what fraction of labels are NJ
 mean(label == "FL")
# for what fraction of cases is before greater than after
 mean(before > after)
 # what fraction of before values exceed two standard deviations from the mean of before values
 mean(before - mean(before) > 2*sd(before))
 # fraction of time series values that are larger than the value taken immediately prior
 mean(diff(time_series) > 0)
```

tabulate one factor or build a contingency table from multiple factors
```{r 9.3 Tabulating Factors and Creating Contingency Tables}
f1 <- factor(
  sample(letters[1:5], size = 100, prob = c(17,17,22,20,24), replace = TRUE),
  levels = c("a", "b", "c", "d", "e"))

f2 <- factor(
  sample(letters[6:8], size = 100, replace = TRUE),
  levels = c("f", "g", "h"))

# produce counts of factor f1
table(f1)
# produce a contingency table for f1 and f2
table(f1, f2)
# will the table function work with three factors?

# also see xtabs
```

test two categorical variables for independence using the chi-squared test
```{r 9.4 Testing Categorical Variables for Independence}
set.seed(42)
initial <- factor(sample(c("Yes", "No", "Maybe"), 100, replace = TRUE))
outcome <- factor(sample(c("Pass", "Fail"), 100, replace = TRUE))
summary(table(initial,outcome))
# chisq.test() also does this 
```

Given a fraction f, you want to know the corresponding quantile of your data.
```{r 9.5 Calculating Quantiles (and Quartiles) of a Dataset}
# find the observation at the 95th quantile of var
set.seed(42)
var <- rnorm(100, mean = 100, sd = 20)
quantile(vec, 0.95)
# find the observations expected at each quartile (you should only call one command)
quantile(vec)
# which observation in vec delimits the lower 5% of the data
quantile(vec, 0.05)
# using only one command, return the observations at the 5th and 95th percentile of vec
quantile(vec, c(0.5, 0.95))
# what is the types argument and how many types are there?
```

Given an observation x from your data, what is its corresponding quantile
```{r 9.6 Inverting a Quantile}
# what quantile is a value of 100 in vector "vec"
mean(vec<100)
```

calculate the corresponding z-scores for all data elements
AKA Normalize the data
```{r 9.7 Converting Data to Z-Scores}
# what is a z score
# convert the data to z scores in vec
# normalize the data in vec
scale(vec)
# normalize a single y value relative to dataset x (review the formula for a z score)
y <- mean(vec) - 13
(y-mean(vec)) / sd(vec)
```

Given a sample, you want to know if the mean of the population could reasonably be a particular value m
```{r 9.8 Sampling the Mean of a Sample (t-Test)}
sample <- rnorm(75, mean = 100, sd = 15)
m <- 95

# does a t-test support the population mean of the sample to be 95
t.test(sample, mu = m)
# does a t-test support the population mean of the sample to be 100
t.test(sample, mu = 100)
# what is the default mu argument in the t.test() function
```

Given a sample, you want to determine a confidence interval for the populationâ€™s mean.
```{r 9.9 Forming a Confidence Interval for a Mean}
# give a 95% confidence interval for the means of the sample
t.test(sample)
# give a 99% confidence interval for the means of the sample
t.test(sample, conf.level = .99)
```

Given a data sample, what is the confidence interval for the median
```{r9.10 Forming a Confidence Interval for a Median}
# find a 95% conficence interval for the median of sample
wilcox.test(sample, conf.int = TRUE)
# find a 99% confidence interval for the median of sample
wilcox.test(sample, conf.int = 0.99)

```

Given a sample of values from a population consisting of successes and failures, how can you test if the true proportion of successes is p
```{r 9.11 Testing a Sample Proportion}
# what function would be used

# what arguments does the function take

# what does a small p value (typically p<0.05) indicate

# A sports team won 11/20 games last season. How confident should you be that next season the team will win over half their games
```

Given a sample of values from a population consisting of successes and failures. based on the sample data, create a confidence interval for the population's proportion of success
```{r 9.12 Forming a Confidence Interval for a Proportion}
# The price of a good rose 6 times in the last 9 'market events'. Obtain a 99% confidence interval of the true proportion of times the good's price increases in a 'market event'.
prop.test(x = 6, n =9, conf.level = .99)
```

test if each data sample is from a normally distributed population
```{r 9.13 Testing for Normality}
set.seed(100)
sample1 <- sample(rnorm(100), 30)
sample2 <- sample(rexp(100), 30)

# what function can be used to test this
# what arguments does it take
# what is the output and how should it be interpreted

shapiro.test(sample1)
shapiro.test(sample2)

# what is the package "nortest"
# name two graphical tools used to assess normality
```

given a sequence of binary values: yes/no, 0/1, true/false, or other two-valued data, evaluate if the sequence is random?
```{r 9.14 Testing for Runs}
seq1 <- rep(c(TRUE, FALSE), 50)
seq2 <- sample(seq1, 30, replace = TRUE)

tseries::runs.test(as.factor(seq1))
tseries::runs.test(as.factor(seq2))

# what test can be used
# what are the inputs
# what is the output and how should it be interpreted

```

Given one sample each from two populations, test if the two populations have the same mean
```{r 9.15 Comparing the Means of Two Samples}
# what test can be used
t.test()

# what are the arguments of the test
"x,y, alternative, paired"

# what is the output and should it be interpreted
"a small p value indicates that the means are from different samples"

# what are the assumptions of the test
"if either sample size is fewer than 20 data points, the populations must be normally distributed"

"if the two populations have the same variance, specify var.equal  = TRUE to make the test less conservative"

"Conservative basically means erring on the side of caution when testing, preferring inconclusive results to false results"

# what test should be considered if the populations are not normally distributed and either sample is small
"Wilcoxin-Mann_Whitney test"
```

Given two samples from different populations with similar shapes, test if one population shifted to the left or right of the other
```{r 9.16 Comparing the Locations of Two Samples Nonparametrically}
# what function can be used
"wilcoxin-mann-whitney test"
wilcox.test()

# what are the arguments
"x,y,paired"

# what is the output and how should it be interpreted
"small p value, the populations are likley shifted"
```

Is the correlation between two given variables statistically significant
```{r 9.17 Testing a Correlation for Significance}
# what function can be used, does this depend on the population distribution
"pearsons correlation for normal
spearman correlation for non-normal"
cor.test()
# what are the arguments
"x,y,method"
# what is the output and how should it be interpreted
"small p-value, significant correlation
it also gives the correlation"

```

Given binary samples from two groups (Success/failure), do the groups have equal proportions of successes 
?? WHAT IS THE DIFFEWRENCE BETWEEN GROUP AND POPULATION??
```{r 9.18 Testing Groups for Equal Proportions}
# what function can be used
"proportion test"
prop.test()

# what are the arguments
"number of succeses, number of trials"

# what is the output and how should it be interpreted
"small p, proportions are significantly different"

# The first teacher gave 14/38 students an A. The second teacher gave 10/40 students an A. Is the first teacher awarding significantly more A's than the second teacher. 
successes <- c(14, 10)
trials <- c(38,40)

prop.test(successes, trials)
```
Compare the means of multiple samples from different groups
```{r 9.19 Performing Pairwise Comparisons Between Group Means}
# what function can be used
"pairwise t test can be used"
pairwise.t.test()

# what are the arguments
"data, factor to group by"

# what is the output and how should it be interpreted
"small p value, staticically different means"

# compare mean values grouped by the indicator (grade level) from the df "comb" 
freshmen <- rnorm(30, 80, 20)
sophomores <- rnorm(30, 85, 20)
juniors <- rnorm(30, 100, 20)

comb <- stack(list(fresh = freshmen, soph = sophomores, jrs = juniors))

pairwise.t.test(comb$values, comb$ind)
```

Given two samples, test if they came from the same distribution
```{r 9.20 Testing Two Samples for the Same Distribution}
# what function can be used
"Kolmogorov-Smirnov test"
ks

# what are the arguments
"the two samples"

# what is the output and how should it be interpreted
"small p value, different distributions"

# what conditions must be met to use this test
"normalcy not required"

```

